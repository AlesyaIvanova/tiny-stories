# Tiny Stories

This repository contains the source code for a lightweight GPT-like Transformer model designed to generate short stories for children.

The model is trained on the [TinyStories](https://arxiv.org/abs/2305.07759) dataset and outperforms GPT-2 XL in terms of generation quality when evaluated on factual prompts, reasoning prompts, and consistency (context-tracking) prompts.

A description of the experiments conducted and an analysis of the results can be found in the [Tiny_Stories.pdf](https://github.com/AlesyaIvanova/tiny-stories/blob/main/Tiny_Stories.pdf).
